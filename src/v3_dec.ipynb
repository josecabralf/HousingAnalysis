{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Format import *\n",
    "from config import *\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"df = pd.read_excel(f\"{path_unify}2023-12-01_df.xlsx\")\n",
    "\n",
    "data = DistanceCalculator().calcular_distancias(df)\n",
    "data = DataFilter().formatDF(data)\n",
    "data.to_csv(\"../Data/test/filt_12_01.csv\", sep=\";\", index=False)\"\"\"\n",
    "\n",
    "data = pd.read_csv(\"../Data/test/filt_12_01.csv\", sep=\";\")\n",
    "data = data.loc[data[\"tipoPropiedad\"] != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = ['terrenoEdificado', 'coordX', 'coordY', 'barrioID', 'ano', 'mes', 'dia']\n",
    "data_for_clustering = data[features]\n",
    "\n",
    "# Escalar los datos para que todas las características tengan la misma escala\n",
    "kmeans_scaler = StandardScaler()\n",
    "scaled_data = kmeans_scaler.fit_transform(data_for_clustering)\n",
    "\n",
    "# Determinar el número óptimo de clusters utilizando el método del codo\n",
    "wcss = []\n",
    "for i in range(1, 15):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=100, random_state=42)\n",
    "    kmeans.fit(scaled_data)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Visualizar el método del codo para encontrar el número óptimo de clusters\n",
    "plt.plot(range(1, 15), wcss)\n",
    "plt.title('Método del Codo')\n",
    "plt.xlabel('Número de Clusters')\n",
    "plt.ylabel('WCSS')  # Within-Cluster Sum of Squares\n",
    "plt.show()\n",
    "\n",
    "n_clusters = 8\n",
    "kmeans = KMeans(n_clusters=n_clusters, init='k-means++', max_iter=500, n_init=200, random_state=42)\n",
    "clusters = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# Agregar la información de los clusters al DataFrame original\n",
    "data['clusterKM'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = ['tipoPropiedad', 'terrenoEdificado', \n",
    "            'cantDormitorios', 'cantBanos',\n",
    "            'barrioID', 'coordX', 'coordY', \n",
    "            'transporteCercano', 'saludCercana', \n",
    "            'ano', 'mes', 'clusterKM']\n",
    "data_analisis = data[features]\n",
    "target = data[\"precioUSD\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_analisis, target, train_size=0.8, random_state=33)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('knn1', 0.5636123951855962),\n",
       " ('knn2', 0.6507887855101081),\n",
       " ('knn3', 0.6793320196117629),\n",
       " ('knn4', 0.6905869836139874),\n",
       " ('knn5', 0.7015268563007065),\n",
       " ('knn6', 0.7099557890167736),\n",
       " ('knn7', 0.7080817660608002),\n",
       " ('knn8', 0.7071151414373955),\n",
       " ('knn9', 0.7081056487871125),\n",
       " ('knn10', 0.709083853761895),\n",
       " ('knn11', 0.7093460752637485),\n",
       " ('knn12', 0.7089680293989774),\n",
       " ('knn13', 0.7100686269297889),\n",
       " ('knn14', 0.7082369808935916),\n",
       " ('knn15', 0.7084883222859647),\n",
       " ('knn16', 0.7077272747431483),\n",
       " ('knn17', 0.7064190165517757),\n",
       " ('knn18', 0.70586973994986),\n",
       " ('knn19', 0.7047095377901087)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = dict()\n",
    "r2_scores = []\n",
    "for i in range(1, 20):\n",
    "    models[f'knn{i}'] = KNeighborsRegressor(n_neighbors=i, weights='distance', algorithm='ball_tree')\n",
    "    m = KNeighborsRegressor(n_neighbors=i, weights='distance', algorithm='ball_tree')\n",
    "    m.fit(X_train_scaled, y_train)\n",
    "    scores_r2 = cross_val_score(m, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "    r2_scores.append((f'knn{i}', scores_r2.mean()))\n",
    "    \n",
    "r2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando Random Forest...\n",
      "Random Forest: r2 = 0.7557865627423689, depth = 17\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "print(\"Creando Random Forest...\")\n",
    "\n",
    "best_depth = 0\n",
    "best_r2 = 0\n",
    "\n",
    "for i in range(1, 20):\n",
    "    random_forest_model = RandomForestRegressor(n_estimators=200, random_state=42, max_depth=i)\n",
    "    random_forest_model.fit(X_train_scaled, y_train)\n",
    "    r2 = cross_val_score(random_forest_model, X_train_scaled, y_train, cv=5, scoring='r2').mean()\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_depth = i\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "models['RF'] = RandomForestRegressor(n_estimators=200, random_state=42, max_depth=best_depth)\n",
    "\n",
    "r2_scores.append(('RF', best_r2))\n",
    "print(f\"Random Forest: r2 = {best_r2}, depth = {best_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando XGBoost...\n",
      "XGBoost: r2 = 0.767658794421455, depth = 6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "print(\"Creando XGBoost...\")\n",
    "\n",
    "best_depth = 0\n",
    "best_r2 = 0\n",
    "\n",
    "for i in range(1, 20):\n",
    "    gradient_boosting_model = GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=i, random_state=42)\n",
    "    gradient_boosting_model.fit(X_train_scaled, y_train)\n",
    "    r2 = cross_val_score(gradient_boosting_model, X_train_scaled, y_train, cv=5, scoring='r2').mean()\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_depth = i\n",
    "    else:\n",
    "        break\n",
    "\n",
    "models['GBX'] = RandomForestRegressor(n_estimators=200, random_state=42, max_depth=best_depth)\n",
    "\n",
    "r2_scores.append(('GBX', best_r2))\n",
    "print(f\"XGBoost: r2 = {best_r2}, depth = {best_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando AdaBoost con Decision Tree...\n",
      "AdaBoost DT: r2 = 0.7606965359912212, depth = 11\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "print(\"Creando AdaBoost con Decision Tree...\")\n",
    "\n",
    "best_depth = 0\n",
    "best_r2 = 0\n",
    "\n",
    "for i in range(5, 20):\n",
    "    ada_boost_model = AdaBoostRegressor(DecisionTreeRegressor(max_depth=i), n_estimators=200, random_state=42)\n",
    "    ada_boost_model.fit(X_train_scaled, y_train)\n",
    "    r2 = cross_val_score(ada_boost_model, X_train_scaled, y_train, cv=5, scoring='r2').mean()\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_depth = i\n",
    "    else:\n",
    "        break\n",
    "\n",
    "models['ABX-DT'] = AdaBoostRegressor(DecisionTreeRegressor(max_depth=best_depth), n_estimators=200, random_state=42)\n",
    "\n",
    "r2_scores.append(('ABX-DT', best_r2))\n",
    "print(f\"AdaBoost DT: r2 = {best_r2}, depth = {best_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GBX', 0.7674925196931456),\n",
       " ('ABX-DT', 0.7606340042547588),\n",
       " ('RF', 0.7576072992256915)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_scores = sorted(r2_scores, key=lambda x: x[1], reverse=True)\n",
    "r2_scores = [m for m in r2_scores if m[1] > 0.75]\n",
    "r2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GBX': RandomForestRegressor(max_depth=6, n_estimators=200, random_state=42),\n",
       " 'ABX-DT': AdaBoostRegressor(estimator=DecisionTreeRegressor(max_depth=11),\n",
       "                   n_estimators=200, random_state=42),\n",
       " 'RF': RandomForestRegressor(max_depth=16, n_estimators=200, random_state=42)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_models = dict()\n",
    "for m in r2_scores:\n",
    "    top_models[m[0]] = models[m[0]]\n",
    "top_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando Voting...\n",
      "Voting: r2 = 0.7537507250601203\n",
      "Voting: r2 = 0.7630196386479958, rmse = 39509.93901549374\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "print(\"Creando Voting...\")\n",
    "voting_model = VotingRegressor(estimators=list(top_models.items()))\n",
    "voting_model.fit(X_train_scaled, y_train)\n",
    "r2 = cross_val_score(voting_model, X_train_scaled, y_train, cv=5, scoring='r2').mean()\n",
    "\n",
    "print(f\"Voting: r2 = {r2}\")\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "voting_preds = voting_model.predict(X_test_scaled)\n",
    "r2_ensamble = r2_score(y_test, voting_preds)\n",
    "rmse_ensamble = np.sqrt(mean_squared_error(y_test, voting_preds))\n",
    "\n",
    "print(f\"Voting: r2 = {r2_ensamble}, rmse = {rmse_ensamble}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando Stacking...\n",
      "Voting: r2 = 0.7636095395906397\n",
      "Voting: r2 = 0.7853625661272382, rmse = 37601.304692903985\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "print(\"Creando Stacking...\")\n",
    "stacking_model = StackingRegressor(estimators=list(top_models.items()), n_jobs=2)\n",
    "stacking_model.fit(X_train_scaled, y_train)\n",
    "r2 = cross_val_score(stacking_model, X_train_scaled, y_train, cv=5, scoring='r2').mean()\n",
    "\n",
    "print(f\"Voting: r2 = {r2}\")\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "stacking_preds = stacking_model.predict(X_test_scaled)\n",
    "r2_ensamble = r2_score(y_test, stacking_preds)\n",
    "rmse_ensamble = np.sqrt(mean_squared_error(y_test, stacking_preds))\n",
    "\n",
    "print(f\"Voting: r2 = {r2_ensamble}, rmse = {rmse_ensamble}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
