{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Format import *\n",
    "from config import *\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data = pd.read_csv('../Data/test/all_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = ['tipoPropiedad', 'terrenoEdificado', \n",
    "            'cantDormitorios', 'cantBanos',\n",
    "            'barrioID', 'coordX', 'coordY', \n",
    "            'transporteCercano', 'saludCercana', \n",
    "            'ano', 'mes']\n",
    "data_analisis = data[features]\n",
    "target = data[\"precioUSD\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_analisis, target, train_size=0.8, random_state=33)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict()\n",
    "r2_scores = []\n",
    "for i in range(1, 20):\n",
    "    models[f'knn{i}'] = KNeighborsRegressor(n_neighbors=i, weights='distance', algorithm='ball_tree')\n",
    "    m = KNeighborsRegressor(n_neighbors=i, weights='distance', algorithm='ball_tree')\n",
    "    m.fit(X_train_scaled, y_train)\n",
    "    scores_r2 = cross_val_score(m, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "    r2_scores.append((f'knn{i}', scores_r2.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando Random Forest...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'r2_scores.append((\\'RF\\', best_r2))\\nprint(f\"Random Forest: r2 = {best_r2}, depth = {best_depth}\")'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "print(\"Creando Random Forest...\")\n",
    "\n",
    "best_depth = 18\n",
    "\n",
    "random_forest_model = RandomForestRegressor(n_estimators=200, random_state=42, max_depth=best_depth)\n",
    "random_forest_model.fit(X_train_scaled, y_train)\n",
    "best_r2 = cross_val_score(random_forest_model, X_train_scaled, y_train, cv=5, scoring='r2').mean()\n",
    "    \n",
    "models['RF'] = RandomForestRegressor(n_estimators=200, random_state=42, max_depth=best_depth)\n",
    "\n",
    "r2_scores.append(('RF', best_r2))\n",
    "print(f\"Random Forest: r2 = {best_r2}, depth = {best_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando XGBoost...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'r2_scores.append((\\'GBX\\', best_r2))\\nprint(f\"XGBoost: r2 = {best_r2}, depth = {best_depth}\")'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "print(\"Creando XGBoost...\")\n",
    "\n",
    "best_depth = 8\n",
    "\n",
    "gradient_boosting_model = GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=best_depth, random_state=42)\n",
    "gradient_boosting_model.fit(X_train_scaled, y_train)\n",
    "best_r2 = cross_val_score(gradient_boosting_model, X_train_scaled, y_train, cv=5, scoring='r2').mean()\n",
    "\n",
    "models['GBX'] = RandomForestRegressor(n_estimators=200, random_state=42, max_depth=best_depth)\n",
    "\n",
    "r2_scores.append(('GBX', best_r2))\n",
    "print(f\"XGBoost: r2 = {best_r2}, depth = {best_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando AdaBoost con Decision Tree...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'r2_scores.append((\\'ABX-DT\\', best_r2))\\nprint(f\"AdaBoost DT: r2 = {best_r2}, depth = {best_depth}\")'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "print(\"Creando AdaBoost con Decision Tree...\")\n",
    "\n",
    "best_depth = 14\n",
    "\n",
    "ada_boost_model = AdaBoostRegressor(DecisionTreeRegressor(max_depth=best_depth), n_estimators=200, random_state=42)\n",
    "ada_boost_model.fit(X_train_scaled, y_train)\n",
    "best_r2 = cross_val_score(ada_boost_model, X_train_scaled, y_train, cv=5, scoring='r2').mean()\n",
    "\n",
    "models['ABX-DT'] = AdaBoostRegressor(DecisionTreeRegressor(max_depth=best_depth), n_estimators=200, random_state=42)\n",
    "\n",
    "r2_scores.append(('ABX-DT', best_r2))\n",
    "print(f\"AdaBoost DT: r2 = {best_r2}, depth = {best_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores = sorted(r2_scores, key=lambda x: x[1], reverse=True)\n",
    "r2_scores = [m for m in r2_scores if m[1] > 0.73]\n",
    "r2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GBX': RandomForestRegressor(max_depth=8, n_estimators=200, random_state=42),\n",
       " 'ABX-DT': AdaBoostRegressor(estimator=DecisionTreeRegressor(max_depth=14),\n",
       "                   n_estimators=200, random_state=42),\n",
       " 'RF': RandomForestRegressor(max_depth=18, n_estimators=200, random_state=42),\n",
       " 'knn8': KNeighborsRegressor(algorithm='ball_tree', n_neighbors=8, weights='distance'),\n",
       " 'knn7': KNeighborsRegressor(algorithm='ball_tree', n_neighbors=7, weights='distance'),\n",
       " 'knn9': KNeighborsRegressor(algorithm='ball_tree', n_neighbors=9, weights='distance'),\n",
       " 'knn10': KNeighborsRegressor(algorithm='ball_tree', n_neighbors=10, weights='distance'),\n",
       " 'knn11': KNeighborsRegressor(algorithm='ball_tree', n_neighbors=11, weights='distance'),\n",
       " 'knn6': KNeighborsRegressor(algorithm='ball_tree', n_neighbors=6, weights='distance'),\n",
       " 'knn12': KNeighborsRegressor(algorithm='ball_tree', n_neighbors=12, weights='distance')}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_models = dict()\n",
    "for m in r2_scores:\n",
    "    top_models[m[0]] = models[m[0]]\n",
    "top_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando Voting...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'voting_model.fit(X_train_scaled, y_train)\\nr2 = cross_val_score(voting_model, X_train_scaled, y_train, cv=5, scoring=\\'r2\\').mean()\\n\\nprint(f\"Voting: r2 = {r2}\")\\n\\nX_test_scaled = scaler.transform(X_test)\\nvoting_preds = voting_model.predict(X_test_scaled)\\nr2_ensamble = r2_score(y_test, voting_preds)\\nrmse_ensamble = np.sqrt(mean_squared_error(y_test, voting_preds))\\n\\nprint(f\"Voting: r2 = {r2_ensamble}, rmse = {rmse_ensamble}\")'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def objective(weights):\n",
    "    weights_dict = dict(zip(top_models.keys(), weights))\n",
    "    weighted_ensemble = VotingRegressor(estimators=list(top_models.items()), weights=list(weights_dict.values()))\n",
    "    weighted_ensemble.fit(X_train, y_train)\n",
    "    r2 = cross_val_score(weighted_ensemble, X_train, y_train, cv=5, scoring='r2').mean()\n",
    "    print(f\"r2 = {r2}, weights = {weights}\")\n",
    "    return -r2\n",
    "\n",
    "print(\"Calculando pesos optimos...\")\n",
    "initial_weights = [-0.23468363,  0.75368092,  0.33406547, -0.15421233,  0.03304426, -0.00184314, 0.09632083, \n",
    "                   -0.01377198,  0.24562255, -0.05822294]\n",
    "constraints = ({'type': 'eq', 'fun': lambda w: 1 - sum(w)})\n",
    "result = minimize(objective, initial_weights, constraints=constraints)\n",
    "optimal_weights = result.x\n",
    "\n",
    "print(\"Creando Voting...\")\n",
    "voting_model = VotingRegressor(estimators=list(top_models.items()), weights=list(optimal_weights))\n",
    "voting_model.fit(X_train_scaled, y_train)\n",
    "r2 = cross_val_score(voting_model, X_train_scaled, y_train, cv=5, scoring='r2').mean()\n",
    "\n",
    "print(f\"Voting: r2 = {r2}\")\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "voting_preds = voting_model.predict(X_test_scaled)\n",
    "r2_ensamble = r2_score(y_test, voting_preds)\n",
    "rmse_ensamble = np.sqrt(mean_squared_error(y_test, voting_preds))\n",
    "\n",
    "print(f\"Voting: r2 = {r2_ensamble}, rmse = {rmse_ensamble}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r2 = 0.8013229771027949\n",
    "\n",
    "weights = [-0.23468363  0.75368092  0.33406547 -0.15421233  0.03304426 -0.00184314\n",
    "  0.09632083 -0.01377198  0.24562255 -0.05822293]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando Stacking...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/unfitted_stacking.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "print(\"Creando Stacking...\")\n",
    "stacking_model = StackingRegressor(estimators=list(top_models.items()), n_jobs=2)\n",
    "stacking_model.fit(X_train_scaled, y_train)\n",
    "r2 = cross_val_score(stacking_model, X_train_scaled, y_train, cv=5, scoring='r2').mean()\n",
    "\n",
    "print(f\"Voting: r2 = {r2}\")\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "stacking_preds = stacking_model.predict(X_test_scaled)\n",
    "r2_ensamble = r2_score(y_test, stacking_preds)\n",
    "rmse_ensamble = np.sqrt(mean_squared_error(y_test, stacking_preds))\n",
    "\n",
    "print(f\"Voting: r2 = {r2_ensamble}, rmse = {rmse_ensamble}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/stacking.joblib']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(scaler, '../models/scaler.joblib')\n",
    "joblib.dump(voting_model, '../models/voting.joblib')\n",
    "joblib.dump(stacking_model, '../models/stacking.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
